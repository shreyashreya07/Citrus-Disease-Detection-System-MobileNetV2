import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
import json
import pandas as pd

# Paths
test_dir = "dataset/test"
model_path = "saved_models/citrus_mobilenetv2_model.keras"
class_indices_path = "class_indices.json"

# Parameters
img_size = 224
batch_size = 32

# Load model
model = tf.keras.models.load_model(model_path)

# Load class indices
with open(class_indices_path, "r") as f:
    class_indices = json.load(f)

class_names = list(class_indices.keys())

# Test data generator
test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_size, img_size),
    batch_size=batch_size,
    class_mode="categorical",
    shuffle=False
)

# Evaluate
loss, acc = model.evaluate(test_generator)
print(f"âœ… Test Accuracy: {acc*100:.2f}%")

# Predictions
y_pred = model.predict(test_generator)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = test_generator.classes

# Confusion Matrix
cm = confusion_matrix(y_true, y_pred_classes)
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.show()

# Classification Report (text + bar chart)
report = classification_report(y_true, y_pred_classes, target_names=class_names, output_dict=True)
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred_classes, target_names=class_names))

df_report = pd.DataFrame(report).transpose()
df_report.iloc[:-1, :3].plot(kind='bar', figsize=(10,6))
plt.title("Classification Report Metrics")
plt.ylabel("Score")
plt.ylim(0, 1)
plt.legend(loc="lower right")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# ROC Curves per class
plt.figure(figsize=(8,6))
for i, class_name in enumerate(class_names):
    fpr, tpr, _ = roc_curve(test_generator.labels == i, y_pred[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{class_name} (AUC = {roc_auc:.2f})")

plt.plot([0,1],[0,1],'--', color="gray")
plt.title("ROC Curves")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.grid(alpha=0.5)
plt.show()
